# Sentimentâ€‘Analysisâ€‘onâ€‘Textualâ€‘Dataâ€‘usingâ€‘OCR

A pipeline that extracts text from images using OCR and performs sentiment analysis on the extracted content. Combines computer vision and NLP to evaluate the tone of visual documents.

## ğŸ” Description

This project scans images (like posters, screenshots, handwritten notes) and uses OCR to extract embedded text. The text is then passed to a sentiment analysis model to classify it as positive, negative, or neutral. This is useful for analyzing content in image-heavy domains like social media or scanned documents.

## ğŸ› ï¸ Techniques

- **Tesseract OCR** is used to extract text from image input. More on [Tesseract OCR](https://github.com/tesseract-ocr/tesseract).
- **Text Preprocessing** includes tokenization, punctuation removal, and lowercasing using regular expressions.
- **TF-IDF Vectorization** to convert raw text into numerical features. See [MDN on TF-IDF](https://developer.mozilla.org/en-US/docs/Glossary/TF-IDF).
- **Naive Bayes classifier** trained to categorize text sentiment.
- Integration of image reading, OCR, preprocessing, vectorization, and prediction in a streamlined pipeline.

## ğŸ“¦ Technologies & Libraries

- [Pytesseract](https://pypi.org/project/pytesseract/) â€“ Python wrapper for Google Tesseract.
- [OpenCV](https://opencv.org/) â€“ used to preprocess image files before OCR.
- [scikit-learn](https://scikit-learn.org/) â€“ for TF-IDF and model training.
- [NLTK](https://www.nltk.org/) â€“ optional support for extended text preprocessing and stop word handling.

## ğŸ—‚ï¸ Project Structure

```
/
â”œâ”€â”€ data/
â”œâ”€â”€ images/
â”œâ”€â”€ models/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ src/
â””â”€â”€ README.md
```

- **data/** â€“ stores sample text data or preprocessed outputs.
- **images/** â€“ input image files for OCR.
- **models/** â€“ stores trained sentiment classifiers and vectorizers.
- **notebooks/** â€“ experiments and development logs.
- **src/** â€“ Python scripts for OCR, preprocessing, training, and sentiment inference.
